{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use in tutorial and development; do not include this `sys.path` change in production:\n",
    "import sys ; sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Statistical Relational Learning with `pslpython`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen there are several ways to work with graph-based data, including: SPARQL queries, graph algorithms traversals, ML embedding, etc.\n",
    "Each of these methods makes trade-offs in terms of:\n",
    "\n",
    "  * computational costs as the graph size scales\n",
    "  * robustness when there is uncertainty or conflicting information in the graph\n",
    "  * formalism (i.e., *analytic solutions*) vs. empirical approaches (i.e., data-driven, machine learning)\n",
    "\n",
    "One way to visualize some of these trade-offs is in the following diagram:\n",
    "\n",
    "<img src=\"https://github.com/DerwenAI/kglab/blob/main/docs/assets/tradeoffs.png?raw=true\" width=\"400\"/>\n",
    "\n",
    "Note in the top/right corner of the diagram that a relatively formal category of graph-based approaches is called [*statistical relational learning*](https://www.cs.umd.edu/srl-book/).\n",
    "The gist is that so much of the *network analysis* that we want to perform can be describe mathematically as [*markov networks*](https://en.wikipedia.org/wiki/Markov_random_field), in terms of probabilistic models.\n",
    "Sometimes these can be quite computationally expensive; for example, hedge funds on Wall Street tend to burn lots of cloud computing on markov models.\n",
    "They are *robust* in terms of being able to work well even with lots of missing or conflicting data, and the *formalism* implies that we can infer mathematical guarantees from the analyis.\n",
    "That's quite the opposite of deep learning models, which are great at predicting sequences of things, but terrible at providing guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there's been much emphasis in industry recently that equates \"artificial intelligence\" with \"deep learning\", although we are also recognizing [*diminishing returns*](https://derwen.ai/s/zf43#33) for methods that rely purely on ever-larger data rates and ever-larger ML models.\n",
    "One path forward will be to combine machine learning with use of *structured knowledge* (i.e., KGs) such that we can avoid \"boiling the oceans\" with purely data-driven approaches when in so many use cases we can leverage domain expertise.\n",
    "\n",
    "In this secton we'll consider one form of statistical relational learning called [*probabilistic soft logic*](https://psl.linqs.org/) (PSL) which is essentially a kind of \"fuzzy logic\" for graphs that has interesting computational qualities.\n",
    "Whereas many kinds of formal graph analysis (e.g., \"traveling salesman problem\") are provably hard and quite expensive in practice, PSL can be solved with a *convex optimization* (e.g., like so many machine learning algorithms).\n",
    "\n",
    "Consider this: we can describe \"rules\" about nodes and relations in a KG, then assign probabilities to specific instances of those rules that are found within our graph.\n",
    "If the probabilities are all *zero* then the system is consistent.\n",
    "As some of the assigned probabilities are increased, then some of the rules become inconsistent.\n",
    "How high (i.e., optimal) of a set of probabilities can we assign while still keeping the system consistent?\n",
    "Alternatively, if we apply a set of rules, then how \"far away\" (probabilistically speaking) is a graph from being logically consistent?\n",
    "\n",
    "This comes in quite handy when we want to combine *semantic technologies* and *machine learning*, or rather when we have explicit rules plus lots of empirical data.\n",
    "Data quality is a persistent problem, so we can leverage PSL to identify which parts of the graph seem the least \"logically consistent\", and therefore need some review and curation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDF representation of the \"simple acquaintances\" example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the examples given for PSL is called [*simple acquaintances*](https://github.com/linqs/psl-examples/tree/master/simple-acquaintances), which uses a graph of some friends, where they live, what interests they share, and then infers who probably knows whom.\n",
    "Some people explicitly do or do not know each other, while other \"knows\" relations can be inferred based on whether two people have lived in the same place or share common interest.\n",
    "\n",
    "The objective is to build a PSL model for [*link prediction*](https://en.wikipedia.org/wiki/Link_prediction), to evaluate the annotations in the friend graph.\n",
    "In this case, we'll assume that the \"knows\" relations have been added from a questionable source (e.g., some third-party dataset) so we'll measure a subset of these relations and determine their likelihood.\n",
    "NB: this is really useful for cleaning up annotations in a large graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load a KG which is an RDF representation of this example, based on a simple extension of the [`foaf`](http://www.foaf-project.org/) vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kglab\n",
    "\n",
    "namespaces = {\n",
    "    \"acq\":  \"http://example.org/stuff/\",\n",
    "    \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n",
    "    }\n",
    "\n",
    "kg = kglab.KnowledgeGraph(\n",
    "    name = \"LINQS simple acquaintance example for PSL\",\n",
    "    base_uri = \"http://example.org/stuff/\",\n",
    "    namespaces = namespaces,\n",
    "    )\n",
    "\n",
    "kg.load_rdf(\"../dat/acq.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `dat/acq.ttl` file to see the people and their relations.\n",
    "Here's a quick visualization of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"tmp.fig04.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12bf8eb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIS_STYLE = {\n",
    "    \"foaf\": {\n",
    "        \"color\": \"orange\",\n",
    "        \"size\": 5,\n",
    "    },\n",
    "    \"acq\":{\n",
    "        \"color\": \"blue\",\n",
    "        \"size\": 30,\n",
    "    },\n",
    "}\n",
    "\n",
    "excludes = [\n",
    "    kg.get_ns(\"rdf\").type,\n",
    "    kg.get_ns(\"rdfs\").domain,\n",
    "    kg.get_ns(\"rdfs\").range,\n",
    "]\n",
    "\n",
    "subgraph = kglab.Subgraph(kg, excludes=excludes)\n",
    "g = subgraph.vis_pyvis(notebook=True, style=VIS_STYLE)\n",
    "\n",
    "g.force_atlas_2based()\n",
    "g.show(\"tmp.fig04.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's serialize this in TTL/Turtle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.save_rdf(\"foo.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the resulting `foo.ttl` file to see how the relations are organized now.\n",
    "Is that more readable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a PSL model\n",
    "\n",
    "Next, we'll use the [`pslpython`](https://pypi.org/project/pslpython/) library implemented in Python (atop Java core software) to define three *predicates* (i.e., relations â€“ similar as in RDF) which are: `Neighbors`, `Likes`, `Knows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pslpython.model import Model\n",
    "from pslpython.partition import Partition\n",
    "from pslpython.predicate import Predicate\n",
    "from pslpython.rule import Rule\n",
    "\n",
    "model = Model(\"simple acquaintances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add each of the predicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pslpython.model.Model at 0x12bfca190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate = Predicate(\"Neighbors\", closed=True, size=2)\n",
    "model.add_predicate(predicate)\n",
    "\n",
    "predicate = Predicate(\"Likes\", closed=True, size=2)\n",
    "model.add_predicate(predicate)\n",
    "\n",
    "predicate = Predicate(\"Knows\", closed=False, size=2)\n",
    "model.add_predicate(predicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll add a set of probabilistic [*rules*](https://psl.linqs.org/wiki/2.2.1/Rule-Specification.html), all with different weights applied:\n",
    "\n",
    "  1. \"Two people who live in the same place are **more** likely to know each other\"\n",
    "  2. \"Two people who don't live in the same place are **less** likely to know each other\"\n",
    "  3. \"Two people who share a common interest are **more** likely to know each other\"\n",
    "  4. \"Two people who both know a third person are **more** likely to know each other\"\n",
    "  5. \"Otherwise, any pair of people are **less** likely to know each other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pslpython.model.Model at 0x12bfca190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_rule(Rule(\"20: Neighbors(P1, L) & Neighbors(P2, L) & (P1 != P2) -> Knows(P1, P2) ^2\"))\n",
    "\n",
    "model.add_rule(Rule(\"5: Neighbors(P1, L1) & Neighbors(P2, L2) & (P1 != P2) & (L1 != L2) -> !Knows(P1, P2) ^2\"))\n",
    "\n",
    "model.add_rule(Rule(\"10: Likes(P1, L) & Likes(P2, L) & (P1 != P2) -> Knows(P1, P2) ^2\"))\n",
    "\n",
    "model.add_rule(Rule(\"5: Knows(P1, P2) & Knows(P2, P3) & (P1 != P3) -> Knows(P1, P3) ^2\"))\n",
    "\n",
    "model.add_rule(Rule(\"5: !Knows(P1, P2) ^2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll add a *commutative* rule such that \"If Person 1 knows Person 2, then Person 2 also knows Person 1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pslpython.model.Model at 0x12bfca190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_rule(Rule(\"Knows(P1, P2) = Knows(P2, P1) .\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the model, we'll clear any pre-existing data from each of the predicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for predicate in model.get_predicates().values():\n",
    "    predicate.clear_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll define a simple helper function, to format a unique URL within our `acq` vocabulary (a simple extension of `foaf`) based on the purely numeric identifiers used within PSL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_id (url):\n",
    "    return url.replace(\"http://example.org/stuff/person_\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query our KG to populate data into the `Neighbors` predicate in the PSL model, based on `foaf:based_near` that represents living near the same locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicate = model.get_predicate(\"Neighbors\")\n",
    "\n",
    "sparql = \"\"\"\n",
    "SELECT DISTINCT ?p1 ?p2\n",
    "  WHERE {\n",
    "      ?p1 foaf:based_near ?l .\n",
    "      ?p2 foaf:based_near ?l .\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = get_person_id(row.p1)\n",
    "    p2 = get_person_id(row.p2)\n",
    "\n",
    "    if p1 != p2:\n",
    "        predicate.add_data_row(Partition.OBSERVATIONS, [p1, p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: these data points are *observations*, i.e., empirical support for the probabilistic model.\n",
    "    \n",
    "Then let's query our KG to populate data into the `Likes` predicate in the PSL model, based on shared interests in `foaf:topic_interest` topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicate = model.get_predicate(\"Likes\")\n",
    "    \n",
    "sparql = \"\"\"\n",
    "SELECT DISTINCT ?p1 ?p2\n",
    "  WHERE {\n",
    "      ?p1 foaf:topic_interest ?t .\n",
    "      ?p2 foaf:topic_interest ?t .\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = get_person_id(row.p1)\n",
    "    p2 = get_person_id(row.p2)\n",
    "\n",
    "    if p1 != p2:\n",
    "        predicate.add_data_row(Partition.OBSERVATIONS, [p1, p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for kicks, let's take a look at the internal representation of a PSL predicate, which is a `pandas` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_types': [<ArgType.UNIQUE_STRING_ID: 'UniqueStringID'>,\n",
       "  <ArgType.UNIQUE_STRING_ID: 'UniqueStringID'>],\n",
       " '_data': {<Partition.OBSERVATIONS: 'observations'>:       0   1    2\n",
       "  0     9   2  1.0\n",
       "  1     9  17  1.0\n",
       "  2     9   4  1.0\n",
       "  3     9   3  1.0\n",
       "  4     9  12  1.0\n",
       "  ..   ..  ..  ...\n",
       "  567  20  18  1.0\n",
       "  568   1  16  1.0\n",
       "  569  15   8  1.0\n",
       "  570  10  18  1.0\n",
       "  571   2  23  1.0\n",
       "  \n",
       "  [572 rows x 3 columns],\n",
       "  <Partition.TARGETS: 'targets'>: Empty DataFrame\n",
       "  Columns: [0, 1, 2]\n",
       "  Index: [],\n",
       "  <Partition.TRUTH: 'truth'>: Empty DataFrame\n",
       "  Columns: [0, 1, 2]\n",
       "  Index: []},\n",
       " '_name': 'LIKES',\n",
       " '_closed': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate = model.get_predicate(\"Likes\")\n",
    "predicate.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load data from the `dat/psl/knows_targets.txt` CSV file, which is a list of `foaf:knows` relations in our graph that we want to analyze.\n",
    "Each of these has an assumed value of `1.0` (true) or `0.0` (false).\n",
    "Our PSL analysis will assign probabilities for each so that we can compare which annotations appear to be suspect and require further review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "\n",
    "targets = []\n",
    "rows_list = []\n",
    "predicate = model.get_predicate(\"Knows\")\n",
    "\n",
    "with open(\"../dat/psl/knows_targets.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    \n",
    "    for i, row in enumerate(reader):\n",
    "        p1, p2 = row\n",
    "        targets.append((p1, p2))\n",
    "    \n",
    "        p1_url = rdflib.URIRef(\"http://example.org/stuff/person_\" + p1)\n",
    "        p2_url = rdflib.URIRef(\"http://example.org/stuff/person_\" + p2)\n",
    "        \n",
    "        if (p1_url, kg.get_ns(\"foaf\").knows, p2_url) in kg.rdf_graph():\n",
    "            truth = 1.0\n",
    "            predicate.add_data_row(Partition.TRUTH, [p1, p2], truth_value=truth)\n",
    "            predicate.add_data_row(Partition.TARGETS, [p1, p2])\n",
    "            rows_list.append({ 0: p1, 1: p2, \"truth\": truth})\n",
    "        elif (p1_url, kg.get_ns(\"acq\").wantsIntro, p2_url) in kg.rdf_graph():\n",
    "            truth = 0.0\n",
    "            predicate.add_data_row(Partition.TRUTH, [p1, p2], truth_value=truth)\n",
    "            predicate.add_data_row(Partition.TARGETS, [p1, p2])\n",
    "            rows_list.append({ 0: p1, 1: p2, \"truth\": truth})\n",
    "        else:\n",
    "            print(\"UNKNOWN\", p1, p2)\n",
    "\n",
    "df_dat = pd.DataFrame(rows_list)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data points are considered to be *ground atoms*, each with a *truth* value set initially.\n",
    "These are also our *targets* for which nodes in the graph to analyze based on the rules.\n",
    "\n",
    "Next, we'll add `foaf:knows` observations which are in the graph, although not among our set of targets.\n",
    "This provides more evidence for the probabilistic inference.\n",
    "Note that since RDF does not allow for representing probabilities on relations, we're using the `acq:wantsIntro` to represent a `foaf:knows` with a `0.0` probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicate = model.get_predicate(\"Knows\")\n",
    "\n",
    "sparql = \"\"\"\n",
    "SELECT ?p1 ?p2\n",
    "  WHERE {\n",
    "      ?p1 foaf:knows ?p2 .\n",
    "  }\n",
    "  ORDER BY ?p1 ?p2\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = get_person_id(row.p1)\n",
    "    p2 = get_person_id(row.p2)\n",
    "    \n",
    "    if (p1, p2) not in targets:\n",
    "        predicate.add_data_row(Partition.OBSERVATIONS, [p1, p2], truth_value=1.0)\n",
    "    \n",
    "sparql = \"\"\"\n",
    "SELECT ?p1 ?p2\n",
    "  WHERE {\n",
    "      ?p1 acq:wantsIntro ?p2 .\n",
    "  }\n",
    "  ORDER BY ?p1 ?p2\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = get_person_id(row.p1)\n",
    "    p2 = get_person_id(row.p2)\n",
    "    \n",
    "    if (p1, p2) not in targets:\n",
    "        predicate.add_data_row(Partition.OBSERVATIONS, [p1, p2], truth_value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to optimize the PSL model â€“ this may take a few minutes to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6704 [pslpython.model PSL] INFO --- 0    [main] INFO  org.linqs.psl.cli.Launcher  - Running PSL CLI Version 2.2.2-5f9a472\n",
      "7102 [pslpython.model PSL] INFO --- 400  [main] INFO  org.linqs.psl.cli.Launcher  - Loading data\n",
      "7401 [pslpython.model PSL] INFO --- 699  [main] INFO  org.linqs.psl.cli.Launcher  - Data loading complete\n",
      "7402 [pslpython.model PSL] INFO --- 700  [main] INFO  org.linqs.psl.cli.Launcher  - Loading model from /var/folders/zz/2ffrqd5j7n52x67qd94h_r_h0000gp/T/psl-python/simple acquaintances/simple acquaintances.psl\n",
      "7611 [pslpython.model PSL] INFO --- 909  [main] INFO  org.linqs.psl.cli.Launcher  - Model loading complete\n",
      "7612 [pslpython.model PSL] INFO --- 909  [main] INFO  org.linqs.psl.cli.Launcher  - Starting inference with class: org.linqs.psl.application.inference.MPEInference\n",
      "7786 [pslpython.model PSL] INFO --- 1084 [main] INFO  org.linqs.psl.application.inference.MPEInference  - Grounding out model.\n",
      "13676 [pslpython.model PSL] INFO --- 6974 [main] INFO  org.linqs.psl.application.inference.MPEInference  - Grounding complete.\n",
      "14159 [pslpython.model PSL] INFO --- 7458 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Beginning inference.\n",
      "34875 [pslpython.model PSL] WARNING --- 28173 [main] WARN  org.linqs.psl.reasoner.admm.ADMMReasoner  - No feasible solution found. 112 constraints violated.\n",
      "34876 [pslpython.model PSL] INFO --- 28173 [main] INFO  org.linqs.psl.reasoner.admm.ADMMReasoner  - Optimization completed in 10796 iterations. Objective: 147032.2, Feasible: false, Primal res.: 0.16986337, Dual res.: 0.008882373\n",
      "34876 [pslpython.model PSL] INFO --- 28174 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Inference complete.\n",
      "34877 [pslpython.model PSL] INFO --- 28174 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Writing results to Database.\n",
      "34912 [pslpython.model PSL] INFO --- 28209 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Results committed to database.\n",
      "34913 [pslpython.model PSL] INFO --- 28210 [main] INFO  org.linqs.psl.cli.Launcher  - Inference Complete\n"
     ]
    }
   ],
   "source": [
    "PSL_OPTIONS = {\n",
    "    \"log4j.threshold\": \"INFO\"\n",
    "}\n",
    "\n",
    "results = model.infer(additional_cli_optons=[], psl_config=PSL_OPTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the results.\n",
    "We'll get a `pandas` DataFrame describing the targets in the `Knows` predicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.994971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.988278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0.005603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1     truth\n",
       "0  7  15  0.001802\n",
       "1  7  17  0.004209\n",
       "2  7  18  0.994971\n",
       "3  7  12  0.988278\n",
       "4  6  19  0.005603"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate = model.get_predicates()[\"KNOWS\"]\n",
    "df = results[predicate]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the \"truth\" values from our targets, with their probabilities from the inference provided by the PSL model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>truth</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>-0.005029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.988278</td>\n",
       "      <td>-0.011722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.005603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.243230</td>\n",
       "      <td>-0.756770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.990197</td>\n",
       "      <td>-0.009803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.240251</td>\n",
       "      <td>0.240251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.982447</td>\n",
       "      <td>-0.017553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.232082</td>\n",
       "      <td>-0.767918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.996413</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>-0.002823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.997902</td>\n",
       "      <td>-0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998483</td>\n",
       "      <td>-0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0.209273</td>\n",
       "      <td>0.209273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0.977178</td>\n",
       "      <td>-0.022822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0.977073</td>\n",
       "      <td>-0.022927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>-0.013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.980332</td>\n",
       "      <td>-0.019668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983497</td>\n",
       "      <td>-0.016503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983989</td>\n",
       "      <td>-0.016011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.242896</td>\n",
       "      <td>-0.757104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.002601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.003746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991533</td>\n",
       "      <td>-0.008467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.986128</td>\n",
       "      <td>-0.013872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.004889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.971346</td>\n",
       "      <td>-0.028654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.005678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>-0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.240558</td>\n",
       "      <td>0.240558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>-0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>-0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987152</td>\n",
       "      <td>-0.012848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986233</td>\n",
       "      <td>-0.013767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.209213</td>\n",
       "      <td>0.209213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970383</td>\n",
       "      <td>-0.029617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>-0.000872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211159</td>\n",
       "      <td>0.211159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997292</td>\n",
       "      <td>-0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.981102</td>\n",
       "      <td>-0.018898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997934</td>\n",
       "      <td>-0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.986071</td>\n",
       "      <td>-0.013929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986596</td>\n",
       "      <td>-0.013404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.231896</td>\n",
       "      <td>-0.768104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.008317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.989765</td>\n",
       "      <td>-0.010235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969772</td>\n",
       "      <td>-0.030228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983628</td>\n",
       "      <td>-0.016372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977122</td>\n",
       "      <td>-0.022878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>-0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984063</td>\n",
       "      <td>-0.015937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.003479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986645</td>\n",
       "      <td>-0.013355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991640</td>\n",
       "      <td>-0.008360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235508</td>\n",
       "      <td>0.235508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.245457</td>\n",
       "      <td>-0.754543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.256432</td>\n",
       "      <td>-0.743568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998469</td>\n",
       "      <td>-0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997036</td>\n",
       "      <td>-0.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.995007</td>\n",
       "      <td>-0.004993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977483</td>\n",
       "      <td>-0.022517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>-0.743717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.235547</td>\n",
       "      <td>0.235547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.986442</td>\n",
       "      <td>-0.013558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.986276</td>\n",
       "      <td>-0.013724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.245360</td>\n",
       "      <td>-0.754640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.991980</td>\n",
       "      <td>-0.008020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.003489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.990416</td>\n",
       "      <td>-0.009584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>-0.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.005280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0.982158</td>\n",
       "      <td>-0.017842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.988231</td>\n",
       "      <td>-0.011769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0.981665</td>\n",
       "      <td>-0.018335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.006087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.988324</td>\n",
       "      <td>-0.011676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.006532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0.989004</td>\n",
       "      <td>-0.010996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0.995383</td>\n",
       "      <td>-0.004617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.004381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.992632</td>\n",
       "      <td>-0.007368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991031</td>\n",
       "      <td>-0.008969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>0.977831</td>\n",
       "      <td>-0.022169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0.230091</td>\n",
       "      <td>0.230091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>0.204120</td>\n",
       "      <td>0.204120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>0.970594</td>\n",
       "      <td>-0.029406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>0.993005</td>\n",
       "      <td>-0.006995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.230129</td>\n",
       "      <td>0.230129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>-0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0.985841</td>\n",
       "      <td>-0.014159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999253</td>\n",
       "      <td>-0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.977510</td>\n",
       "      <td>-0.022490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986158</td>\n",
       "      <td>-0.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.209197</td>\n",
       "      <td>-0.790803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.980120</td>\n",
       "      <td>-0.019880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>0.987335</td>\n",
       "      <td>-0.012665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.209067</td>\n",
       "      <td>-0.790933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.003580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0.203996</td>\n",
       "      <td>0.203996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.003810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983720</td>\n",
       "      <td>-0.016280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.210734</td>\n",
       "      <td>0.210734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.215543</td>\n",
       "      <td>-0.784457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     truth      diff\n",
       "0     7  15  0.001802  0.001802\n",
       "1     7  17  0.004209  0.004209\n",
       "2     7  18  0.994971 -0.005029\n",
       "3     7  12  0.988278 -0.011722\n",
       "4     6  19  0.005603  0.005603\n",
       "5     6  12  0.243230 -0.756770\n",
       "6     6  13  0.990197 -0.009803\n",
       "7     6  14  0.240251  0.240251\n",
       "8     6  16  0.982447 -0.017553\n",
       "9     6  17  0.003867  0.003867\n",
       "10    5  22  0.232082 -0.767918\n",
       "11    5  16  0.996413 -0.003587\n",
       "12    5  17  0.997177 -0.002823\n",
       "13    5  12  0.997902 -0.002098\n",
       "14    5  13  0.998483 -0.001517\n",
       "15    4  15  0.003127  0.003127\n",
       "16    9  19  0.209273  0.209273\n",
       "17    9  17  0.977178 -0.022822\n",
       "18    8  21  0.977073 -0.022927\n",
       "19    8  10  0.986556 -0.013444\n",
       "20    8  12  0.980332 -0.019668\n",
       "21    8  13  0.983497 -0.016503\n",
       "22    7  20  0.003006  0.003006\n",
       "23   13   4  0.983989 -0.016011\n",
       "24   13   7  0.003286  0.003286\n",
       "25   12   6  0.242896 -0.757104\n",
       "26   11   7  0.002601  0.002601\n",
       "27   11   8  0.003746  0.003746\n",
       "28   11   3  0.004295  0.004295\n",
       "29   10   6  0.991533 -0.008467\n",
       "30   10   9  0.986128 -0.013872\n",
       "31   16   7  0.004889  0.004889\n",
       "32   16   8  0.971346 -0.028654\n",
       "33   16   2  0.005678  0.005678\n",
       "34   15   1  0.003524  0.003524\n",
       "35   15   5  0.999346 -0.000654\n",
       "36   14   6  0.240558  0.240558\n",
       "37   14   9  0.986700 -0.013300\n",
       "38   14   0  0.999034 -0.000966\n",
       "39   14   1  0.987152 -0.012848\n",
       "40   14   3  0.986233 -0.013767\n",
       "41   19   9  0.209213  0.209213\n",
       "42   19   1  0.970383 -0.029617\n",
       "43   18   5  0.999128 -0.000872\n",
       "44   18   8  0.002998  0.002998\n",
       "45   17   1  0.211159  0.211159\n",
       "46    0   1  0.997292 -0.002708\n",
       "47   23   9  0.981102 -0.018898\n",
       "48   23   0  0.997934 -0.002066\n",
       "49    3   7  0.986071 -0.013929\n",
       "50   23   2  0.986596 -0.013404\n",
       "51   22   5  0.231896 -0.768104\n",
       "52   22   9  0.008317  0.008317\n",
       "53    2   6  0.989765 -0.010235\n",
       "54   22   1  0.969772 -0.030228\n",
       "55    1   2  0.983628 -0.016372\n",
       "56   21   1  0.977122 -0.022878\n",
       "57    0   7  0.998761 -0.001239\n",
       "58   20   1  0.984063 -0.015937\n",
       "59   20   6  0.003479  0.003479\n",
       "60    7   1  0.986645 -0.013355\n",
       "61    6   7  0.991640 -0.008360\n",
       "62    6   9  0.235508  0.235508\n",
       "63    5   7  0.245457 -0.754543\n",
       "64    5   9  0.256432 -0.743568\n",
       "65    5   2  0.998469 -0.001531\n",
       "66    4   0  0.997036 -0.002964\n",
       "67   10  15  0.995007 -0.004993\n",
       "68    9   1  0.977483 -0.022517\n",
       "69    9   5  0.256283 -0.743717\n",
       "70    9   6  0.235547  0.235547\n",
       "71    9   7  0.986442 -0.013558\n",
       "72    8   7  0.986276 -0.013724\n",
       "73    8   3  0.007129  0.007129\n",
       "74    7   5  0.245360 -0.754640\n",
       "75   12  24  0.991980 -0.008020\n",
       "76   13  10  0.003489  0.003489\n",
       "77   13  11  0.990416 -0.009584\n",
       "78   12  21  0.215400 -0.784600\n",
       "79   12  17  0.005280  0.005280\n",
       "80   11  22  0.982158 -0.017842\n",
       "81   12  10  0.988231 -0.011769\n",
       "82   11  19  0.981665 -0.018335\n",
       "83   16  23  0.006087  0.006087\n",
       "84   16  15  0.988324 -0.011676\n",
       "85   16  12  0.006532  0.006532\n",
       "86   14  23  0.989004 -0.010996\n",
       "87   15  11  0.995383 -0.004617\n",
       "88   14  17  0.004381  0.004381\n",
       "89   14  11  0.992632 -0.007368\n",
       "90   14  13  0.991031 -0.008969\n",
       "91   13  22  0.977831 -0.022169\n",
       "92   19  16  0.009071  0.009071\n",
       "93   18  15  0.000952  0.000952\n",
       "94   18  17  0.230091  0.230091\n",
       "95   17  21  0.204120  0.204120\n",
       "96   17  22  0.970594 -0.029406\n",
       "97   18  12  0.993005 -0.006995\n",
       "98   17  18  0.230129  0.230129\n",
       "99    0  18  0.999130 -0.000870\n",
       "100  20  12  0.985841 -0.014159\n",
       "101   0  15  0.999253 -0.000747\n",
       "102   3  21  0.977510 -0.022490\n",
       "103  23  18  0.002388  0.002388\n",
       "104   3  10  0.986158 -0.013842\n",
       "105  22  21  0.209197 -0.790803\n",
       "106   3  12  0.980120 -0.019880\n",
       "107  22  24  0.987335 -0.012665\n",
       "108  21  24  0.003158  0.003158\n",
       "109   2  11  0.003029  0.003029\n",
       "110  21  22  0.209067 -0.790933\n",
       "111  21  14  0.003580  0.003580\n",
       "112  21  17  0.203996  0.203996\n",
       "113   1  11  0.003810  0.003810\n",
       "114   1  13  0.983720 -0.016280\n",
       "115   1  17  0.210734  0.210734\n",
       "116  21  12  0.215543 -0.784457\n",
       "117   0  22  0.001782  0.001782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat_val = {}\n",
    "\n",
    "for index, row in df_dat.iterrows():\n",
    "    p1 = row[0]\n",
    "    p2 = row[1]\n",
    "    key = (int(p1), int(p2))\n",
    "    dat_val[key] = row[\"truth\"]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    p1 = row[0]\n",
    "    p2 = row[1]\n",
    "    key = (int(p1), int(p2))\n",
    "    df.at[index, \"diff\"] = row[\"truth\"] - dat_val[key]\n",
    "\n",
    "pd.set_option(\"max_rows\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, which of these \"knows\" relations in the graph appears to be suspect, based on our rules plus the other evidence in the graph?\n",
    "\n",
    "Let's visualize a histogram of how the inferred probabilities are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"diff\"].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases there is little or no difference (`0.0 <= d <= 0.2`) in the probabilities for the target relations.\n",
    "However, some appear to be off by a substantial (`-0.8`) amount, which indicates problems in that part of  our graph data.\n",
    "\n",
    "The following rows show where these `foaf:knows` annotations in the graph differs significantly from their truth values predicted by PSL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>truth</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.243230</td>\n",
       "      <td>-0.756770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.232082</td>\n",
       "      <td>-0.767918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.242896</td>\n",
       "      <td>-0.757104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.231896</td>\n",
       "      <td>-0.768104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.245457</td>\n",
       "      <td>-0.754543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.256432</td>\n",
       "      <td>-0.743568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>-0.743717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.245360</td>\n",
       "      <td>-0.754640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>-0.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.209197</td>\n",
       "      <td>-0.790803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.209067</td>\n",
       "      <td>-0.790933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.215543</td>\n",
       "      <td>-0.784457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     truth      diff\n",
       "5     6  12  0.243230 -0.756770\n",
       "10    5  22  0.232082 -0.767918\n",
       "25   12   6  0.242896 -0.757104\n",
       "51   22   5  0.231896 -0.768104\n",
       "63    5   7  0.245457 -0.754543\n",
       "64    5   9  0.256432 -0.743568\n",
       "69    9   5  0.256283 -0.743717\n",
       "74    7   5  0.245360 -0.754640\n",
       "78   12  21  0.215400 -0.784600\n",
       "105  22  21  0.209197 -0.790803\n",
       "110  21  22  0.209067 -0.790933\n",
       "116  21  12  0.215543 -0.784457"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"diff\"] < -0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of [*human-in-the-loop*](https://derwen.ai/d/human-in-the-loop) practices for AI, using PSL along with a KG seems like a great way to leverage machine learning, so that the people can focus on parts of the graph that have the most uncertainty.\n",
    "And, therefore, probably provide the best ROI for investing time+cost into curation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Build a PSL model that tests the \"noodle vs. pancake\" rules used in an earlier example with our recipe KG.\n",
    "Which recipes should be annotated differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "Try representing one of the other [PSL examples](https://github.com/linqs/psl-examples/) using RDF and `kglab`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
