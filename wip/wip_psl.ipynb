{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use in tutorial and development; do not include this `sys.path` change in production:\n",
    "import sys ; sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kglab.kglab.KnowledgeGraph at 0x107383710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kglab\n",
    "\n",
    "namespaces = {\n",
    "    \"acq\":  \"http://example.org/stuff/\",\n",
    "    \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n",
    "    }\n",
    "\n",
    "kg = kglab.KnowledgeGraph(\n",
    "    name = \"LINQS simple acquaintance example for PSL\",\n",
    "    base_uri = \"http://example.org/stuff/\",\n",
    "    namespaces = namespaces,\n",
    "    )\n",
    "\n",
    "kg.load_rdf(\"../dat/acq.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `dat/acq.ttl` file to see the people and their relations.\n",
    "Here's a quick visualization of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"tmp.fig04.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x127df9690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIS_STYLE = {\n",
    "    \"foaf\": {\n",
    "        \"color\": \"orange\",\n",
    "        \"size\": 5,\n",
    "    },\n",
    "    \"acq\":{\n",
    "        \"color\": \"blue\",\n",
    "        \"size\": 30,\n",
    "    },\n",
    "}\n",
    "\n",
    "excludes = [\n",
    "    kg.get_ns(\"rdf\").type,\n",
    "    kg.get_ns(\"rdfs\").domain,\n",
    "    kg.get_ns(\"rdfs\").range,\n",
    "]\n",
    "\n",
    "subgraph = kglab.SubgraphTensor(kg, excludes=excludes)\n",
    "pyvis_graph = subgraph.build_pyvis_graph(notebook=True, style=VIS_STYLE)\n",
    "\n",
    "pyvis_graph.force_atlas_2based()\n",
    "pyvis_graph.show(\"tmp.fig04.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a more specific `Subgraph` to transform the names of `foaf:Person` in the graph, since the PSL rules in this example focus on relations among the people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_iter = kg.rdf_graph().subjects(kg.get_ns(\"rdf\").type, kg.get_ns(\"foaf\").Person)\n",
    "people_urls = [ str(p) for p in sorted(people_iter) ]\n",
    "\n",
    "subgraph = kglab.Subgraph(kg, preload=people_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a PSL model\n",
    "\n",
    "Next, we'll use the [`pslpython`](https://pypi.org/project/pslpython/) library implemented in Python (atop its core library running in Java) to define three *predicates* (i.e., relations – similar as in RDF) which are: `Neighbors`, `Likes`, `Knows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pslpython.model\n",
    "import pslpython.partition\n",
    "import pslpython.predicate\n",
    "import pslpython.rule\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "class PSLModel:\n",
    "    \"\"\"\n",
    "Class representing a [*probabilistic soft logic*](https://psl.linqs.org/) (PSL) model.\n",
    "For PSL-specific terminology used here, see <https://psl.linqs.org/wiki/master/Glossary.html>\n",
    "    \"\"\"\n",
    "\n",
    "    _PSL_OPTIONS: dict = {\n",
    "        \"log4j.threshold\": \"INFO\"\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__ (\n",
    "        self,\n",
    "        *,\n",
    "        name: str = None,\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "Wrapper for constructing a [`pslpython.model.Model`](https://github.com/linqs/psl/blob/master/psl-python/pslpython/model.py).\n",
    "\n",
    "    name:\n",
    "optional name of the PSL model; if not supplied, PSL generates a random name\n",
    "        \"\"\"\n",
    "        self.model = pslpython.model.Model(name)\n",
    "        self.results: dict = {}\n",
    "\n",
    "\n",
    "    def add_predicate (\n",
    "        self,\n",
    "        raw_name: str,\n",
    "        closed: bool,\n",
    "        *,\n",
    "        size: int = None,\n",
    "        arg_types = None,\n",
    "        ) -> \"PSLModel\":\n",
    "        \"\"\"\n",
    "Add a [`pslpython.predicate.Predicate`](https://github.com/linqs/psl/blob/master/psl-python/pslpython/predicate.py) to this model.\n",
    "Enough details must be supplied for PSL to infer the number and types of each predicate's arguments.\n",
    "\n",
    "    raw_name:\n",
    "name of the predicate; must be unique among all of the predicates\n",
    "\n",
    "    closed:\n",
    "indicates that this predicate is fully observed, i.e., all substitutions of this predicate have known values and will behave as evidence for inference; otherwise, if `False` then infer some values of this predicate\n",
    "\n",
    "    size:\n",
    "optional, the number of arguments for this predicate\n",
    "\n",
    "    arg_types:\n",
    "optional, a list of types for the arguments for this predicate; all arguments will default to string\n",
    "            \n",
    "    returns:\n",
    "this PSL model – use for method chaining\n",
    "        \"\"\"\n",
    "        predicate = pslpython.predicate.Predicate(\n",
    "            raw_name,\n",
    "            closed=closed,\n",
    "            size=size,\n",
    "            arg_types=arg_types,\n",
    "            )\n",
    "        \n",
    "        self.model.add_predicate(predicate)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_rule (\n",
    "        self,\n",
    "        rule_string: str,\n",
    "        *,\n",
    "        weighted: bool = None,\n",
    "        weight: float = None,\n",
    "        squared: bool = None,\n",
    "        ) -> \"PSLModel\":\n",
    "        \"\"\"\n",
    "Add a [`pslpython.rule.Rule`](https://github.com/linqs/psl/blob/master/psl-python/pslpython/rule.py) to this model.\n",
    "\n",
    "  * a weighted rule can change its weight or squared status\n",
    "  * a weighted rule cannot convert into an unweighted rule nor visa-versa\n",
    "  * unweighted rules are constraints\n",
    "\n",
    "For more details, see <https://psl.linqs.org/wiki/master/Rule-Specification.html>\n",
    "\n",
    "    rule_string:\n",
    "text representation for specifying the rule\n",
    "\n",
    "    weighted:\n",
    "indicates that this rule is weighted\n",
    "\n",
    "    weight:\n",
    "weight of this rule\n",
    "\n",
    "    squared:\n",
    "indicates that this rule's potential is squared\n",
    "\n",
    "    returns:\n",
    "this PSL model – use for method chaining\n",
    "        \"\"\"\n",
    "        rule = pslpython.rule.Rule(\n",
    "            rule_string=rule_string,\n",
    "            weighted=weighted,\n",
    "            weight=weight,\n",
    "            squared=squared,\n",
    "        )\n",
    "\n",
    "        self.model.add_rule(rule)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def clear_model (\n",
    "        self\n",
    "        ) -> \"PSLModel\":\n",
    "        \"\"\"\n",
    "Clear any pre-existing data from each of the predicates, to initialize the model.\n",
    "\n",
    "    returns:\n",
    "this PSL model – use for method chaining\n",
    "        \"\"\"\n",
    "        for predicate in self.model.get_predicates().values():\n",
    "            predicate.clear_data()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def add_data_row (\n",
    "        self,\n",
    "        predicate_name: str,\n",
    "        partition: pslpython.partition.Partition,\n",
    "        args: list,\n",
    "        *,\n",
    "        truth_value: float = 1.0,\n",
    "        verbose: bool = False,\n",
    "        ) -> \"PSLModel\":\n",
    "        \"\"\"\n",
    "Add a single record to a specified predicate.\n",
    "\n",
    "    predicate_name:\n",
    "name of the specific predicate; name normalization will be handled internally; raises `ModelError` if the predicate name is not found\n",
    "\n",
    "    partition:\n",
    "enum for the partition into which the `data` gets added\n",
    "\n",
    "    args:\n",
    "arguments for the record being added, as a list\n",
    "\n",
    "    truth_value:\n",
    "optional truth value of the record being added\n",
    "\n",
    "    verbose:\n",
    "flag for verbose trace of each added record\n",
    "\n",
    "    returns:\n",
    "this PSL model – use for method chaining\n",
    "        \"\"\"\n",
    "        try:\n",
    "            predicate = self.model.get_predicate(predicate_name)\n",
    "            assert predicate\n",
    "        except:\n",
    "            error = \"Unknown predicate: {}\".format(predicate_name)\n",
    "            raise pslpython.model.ModelError(error)\n",
    "\n",
    "        if verbose:\n",
    "            ic(predicate_name, args)\n",
    "\n",
    "        predicate.add_data_row(\n",
    "            partition,\n",
    "            args=args,\n",
    "            truth_value=truth_value,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def infer (\n",
    "        self,\n",
    "        *,\n",
    "        method: str = \"\",\n",
    "        cli_options: list = None,\n",
    "        psl_config: dict = None,\n",
    "        jvm_options: list = None,\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "Run inference on this model, storing the inferred results in an internal dataframe.\n",
    "\n",
    "    method:\n",
    "the inference method to use\n",
    "\n",
    "    cli_options:\n",
    "additional options to pass to PSL, based on its CLI options; see <https://psl.linqs.org/wiki/master/Configuration.html>\n",
    "\n",
    "    psl_config:\n",
    "configuration options passed directly to the PSL core code; see <https://psl.linqs.org/wiki/master/Configuration-Options.html>\n",
    "\n",
    "    jvm_options:\n",
    "options passed to the JVM running the PSL Java library; most commonly `\"-Xmx\"` and `\"-Xms\"`\n",
    "        \"\"\"\n",
    "        if not cli_options:\n",
    "            cli_options = []\n",
    "\n",
    "        if not psl_config:\n",
    "            psl_config = self._PSL_OPTIONS\n",
    "\n",
    "        if not jvm_options:\n",
    "            jvm_options = []\n",
    "\n",
    "        self.results = self.model.infer(\n",
    "            method=method,\n",
    "            additional_cli_optons=cli_options,\n",
    "            psl_config=psl_config,\n",
    "            jvm_options=jvm_options,\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_results (\n",
    "        self,\n",
    "        predicate_name: str,\n",
    "        ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "Accessor for the inferred results for a specified predicate.\n",
    "\n",
    "    predicate_name:\n",
    "name of the specific predicate; name normalization will be handled internally; raises `ModelError` if the predicate name is not found\n",
    "\n",
    "    returns:\n",
    "inferred values as a [`pandas.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), with columns names for each argument plus the `\"truth\"` value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            predicate = self.model.get_predicate(predicate_name)\n",
    "            assert predicate\n",
    "        except:\n",
    "            error = \"Unknown predicate: {}\".format(predicate_name)\n",
    "            raise pslpython.model.ModelError(error)\n",
    "\n",
    "        return self.results[predicate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "psl = PSLModel(\n",
    "    name = \"simple acquaintances\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add each of the predicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PSLModel at 0x127f40b90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psl.add_predicate(\"Neighbors\", closed=True, size=2)\n",
    "psl.add_predicate(\"Likes\", closed=True, size=2)\n",
    "psl.add_predicate(\"Knows\", closed=False, size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll add a set of probabilistic [*rules*](https://psl.linqs.org/wiki/2.2.1/Rule-Specification.html), all with different weights applied:\n",
    "\n",
    "  1. \"Two people who live in the same place are **more** likely to know each other\"\n",
    "  2. \"Two people who don't live in the same place are **less** likely to know each other\"\n",
    "  3. \"Two people who share a common interest are **more** likely to know each other\"\n",
    "  4. \"Two people who both know a third person are **more** likely to know each other\"\n",
    "  5. \"Otherwise, any pair of people are **less** likely to know each other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PSLModel at 0x127f40b90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psl.add_rule(\"20: Neighbors(P1, L) & Neighbors(P2, L) & (P1 != P2) -> Knows(P1, P2) ^2\")\n",
    "\n",
    "psl.add_rule(\"5: Neighbors(P1, L1) & Neighbors(P2, L2) & (P1 != P2) & (L1 != L2) -> !Knows(P1, P2) ^2\")\n",
    "\n",
    "psl.add_rule(\"10: Likes(P1, L) & Likes(P2, L) & (P1 != P2) -> Knows(P1, P2) ^2\")\n",
    "\n",
    "psl.add_rule(\"5: Knows(P1, P2) & Knows(P2, P3) & (P1 != P3) -> Knows(P1, P3) ^2\")\n",
    "\n",
    "psl.add_rule(\"5: !Knows(P1, P2) ^2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll add a *commutative* rule such that \"If Person 1 knows Person 2, then Person 2 also knows Person 1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PSLModel at 0x127f40b90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psl.add_rule(\"Knows(P1, P2) = Knows(P2, P1) .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the model, we'll clear any pre-existing data from each of the predicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PSLModel at 0x127f40b90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psl.clear_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's query our KG to populate data into the `Neighbors` predicate in the PSL model, based on `foaf:based_near` which represents people who live nearby each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparql = \"\"\"\n",
    "SELECT DISTINCT ?p1 ?p2\n",
    "  WHERE {\n",
    "    ?p1 foaf:based_near ?l .\n",
    "    ?p2 foaf:based_near ?l .\n",
    "    FILTER( ?p1 != ?p2 )\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = subgraph.transform(str(row.p1))\n",
    "    p2 = subgraph.transform(str(row.p2))\n",
    "\n",
    "    psl.add_data_row(\n",
    "        \"Neighbors\",\n",
    "        pslpython.partition.Partition.OBSERVATIONS,\n",
    "        [p1, p2],\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: these data points are *observations*, i.e., empirical support for the probabilistic model.\n",
    "    \n",
    "Then let's query our KG to populate data into the `Likes` predicate in the PSL model, based on shared interests in `foaf:topic_interest` topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparql = \"\"\"\n",
    "SELECT DISTINCT ?p1 ?p2\n",
    "  WHERE {\n",
    "    ?p1 foaf:topic_interest ?t .\n",
    "    ?p2 foaf:topic_interest ?t .\n",
    "    FILTER( ?p1 != ?p2 )\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = subgraph.transform(str(row.p1))\n",
    "    p2 = subgraph.transform(str(row.p2))\n",
    "\n",
    "    psl.add_data_row(\n",
    "        \"Likes\",\n",
    "        pslpython.partition.Partition.OBSERVATIONS,\n",
    "        [p1, p2],\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for kicks, let's take a look at the internal representation of a PSL predicate, which is a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_types': [<ArgType.UNIQUE_STRING_ID: 'UniqueStringID'>,\n",
       "  <ArgType.UNIQUE_STRING_ID: 'UniqueStringID'>],\n",
       " '_data': {<Partition.OBSERVATIONS: 'observations'>:       0   1    2\n",
       "  0     2   0  1.0\n",
       "  1     2  24  1.0\n",
       "  2     2   8  1.0\n",
       "  3     2   4  1.0\n",
       "  4     2  17  1.0\n",
       "  ..   ..  ..  ...\n",
       "  567  13   5  1.0\n",
       "  568   6  16  1.0\n",
       "  569   6  14  1.0\n",
       "  570   6  18  1.0\n",
       "  571  14  24  1.0\n",
       "  \n",
       "  [572 rows x 3 columns],\n",
       "  <Partition.TARGETS: 'targets'>: Empty DataFrame\n",
       "  Columns: [0, 1, 2]\n",
       "  Index: [],\n",
       "  <Partition.TRUTH: 'truth'>: Empty DataFrame\n",
       "  Columns: [0, 1, 2]\n",
       "  Index: []},\n",
       " '_name': 'LIKES',\n",
       " '_closed': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate = psl.model.get_predicate(\"Likes\")\n",
    "predicate.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load data from the `dat/psl/knows_targets.txt` CSV file, which is a list of `foaf:knows` relations in our graph that we want to analyze.\n",
    "Each of these has an assumed value of `1.0` (true) or `0.0` (false).\n",
    "Our PSL analysis will assign probabilities for each so that we can compare which annotations appear to be suspect and require further review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "\n",
    "targets = []\n",
    "rows_list = []\n",
    "\n",
    "with open(\"../dat/psl/knows_targets.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    \n",
    "    for i, row in enumerate(reader):\n",
    "        #p1, p2 = row\n",
    "        p1 = int(row[0])\n",
    "        p2 = int(row[1])\n",
    "        targets.append((p1, p2))\n",
    "    \n",
    "        p1_url = rdflib.URIRef(\"http://example.org/stuff/person_{:02d}\".format(int(p1)))\n",
    "        p2_url = rdflib.URIRef(\"http://example.org/stuff/person_{:02d}\".format(int(p2)))\n",
    "        \n",
    "        if (p1_url, kg.get_ns(\"foaf\").knows, p2_url) in kg.rdf_graph():\n",
    "            truth = 1.0\n",
    "            rows_list.append({ 0: p1, 1: p2, \"truth\": truth})\n",
    "\n",
    "            psl.add_data_row(\n",
    "                \"Knows\",\n",
    "                pslpython.partition.Partition.TRUTH,\n",
    "                [p1, p2],\n",
    "                truth_value=truth,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            psl.add_data_row(\n",
    "                \"Knows\",\n",
    "                pslpython.partition.Partition.TARGETS,\n",
    "                [p1, p2],\n",
    "                verbose=False,\n",
    "            )\n",
    "        elif (p1_url, kg.get_ns(\"acq\").wantsIntro, p2_url) in kg.rdf_graph():\n",
    "            truth = 0.0\n",
    "            rows_list.append({ 0: p1, 1: p2, \"truth\": truth})\n",
    "\n",
    "            psl.add_data_row(\n",
    "                \"Knows\",\n",
    "                pslpython.partition.Partition.TRUTH,\n",
    "                [p1, p2],\n",
    "                truth_value=truth,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            psl.add_data_row(\n",
    "                \"Knows\",\n",
    "                pslpython.partition.Partition.TARGETS,\n",
    "                [p1, p2],\n",
    "                verbose=False,\n",
    "            )\n",
    "        else:\n",
    "            print(\"UNKNOWN\", p1, p2)\n",
    "\n",
    "df_dat = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data points are considered to be *ground atoms*, each with a *truth* value set initially.\n",
    "These are also our *targets* for which nodes in the graph to analyze based on the rules.\n",
    "\n",
    "Next, we'll add `foaf:knows` observations which are in the graph, although not among our set of targets.\n",
    "This provides more evidence for the probabilistic inference.\n",
    "Note that since RDF does not allow for representing probabilities on relations, we're using the `acq:wantsIntro` to represent a `foaf:knows` with a `0.0` probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparql = \"\"\"\n",
    "SELECT ?p1 ?p2\n",
    "  WHERE {\n",
    "    ?p1 foaf:knows ?p2 .\n",
    "  }\n",
    "  ORDER BY ?p1 ?p2\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = subgraph.transform(str(row.p1))\n",
    "    p2 = subgraph.transform(str(row.p2))\n",
    "    \n",
    "    if (p1, p2) not in targets:\n",
    "        psl.add_data_row(\n",
    "            \"Knows\",\n",
    "            pslpython.partition.Partition.OBSERVATIONS,\n",
    "            [p1, p2],\n",
    "            truth_value=1.0,\n",
    "            verbose=False,\n",
    "        )\n",
    "    \n",
    "sparql = \"\"\"\n",
    "SELECT ?p1 ?p2\n",
    "  WHERE {\n",
    "    ?p1 acq:wantsIntro ?p2 .\n",
    "  }\n",
    "  ORDER BY ?p1 ?p2\n",
    "  \"\"\"\n",
    "\n",
    "for row in kg.query(sparql):\n",
    "    p1 = subgraph.transform(str(row.p1))\n",
    "    p2 = subgraph.transform(str(row.p2))\n",
    "    \n",
    "    if (p1, p2) not in targets:\n",
    "        psl.add_data_row(\n",
    "            \"Knows\",\n",
    "            pslpython.partition.Partition.OBSERVATIONS,\n",
    "            [p1, p2],\n",
    "            truth_value=0.0,\n",
    "            verbose=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to run optimization on the PSL model and infer the *grounded atoms*.\n",
    "This may take a few minutes to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10323 [pslpython.model PSL] INFO --- 1    [main] INFO  org.linqs.psl.cli.Launcher  - Running PSL CLI Version 2.2.2-5f9a472\n",
      "10703 [pslpython.model PSL] INFO --- 382  [main] INFO  org.linqs.psl.cli.Launcher  - Loading data\n",
      "10992 [pslpython.model PSL] INFO --- 672  [main] INFO  org.linqs.psl.cli.Launcher  - Data loading complete\n",
      "10994 [pslpython.model PSL] INFO --- 672  [main] INFO  org.linqs.psl.cli.Launcher  - Loading model from /var/folders/zz/2ffrqd5j7n52x67qd94h_r_h0000gp/T/psl-python/simple acquaintances/simple acquaintances.psl\n",
      "11184 [pslpython.model PSL] INFO --- 863  [main] INFO  org.linqs.psl.cli.Launcher  - Model loading complete\n",
      "11185 [pslpython.model PSL] INFO --- 863  [main] INFO  org.linqs.psl.cli.Launcher  - Starting inference with class: org.linqs.psl.application.inference.MPEInference\n",
      "11440 [pslpython.model PSL] INFO --- 1119 [main] INFO  org.linqs.psl.application.inference.MPEInference  - Grounding out model.\n",
      "17288 [pslpython.model PSL] INFO --- 6968 [main] INFO  org.linqs.psl.application.inference.MPEInference  - Grounding complete.\n",
      "17720 [pslpython.model PSL] INFO --- 7400 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Beginning inference.\n",
      "37774 [pslpython.model PSL] WARNING --- 27454 [main] WARN  org.linqs.psl.reasoner.admm.ADMMReasoner  - No feasible solution found. 112 constraints violated.\n",
      "37775 [pslpython.model PSL] INFO --- 27454 [main] INFO  org.linqs.psl.reasoner.admm.ADMMReasoner  - Optimization completed in 10797 iterations. Objective: 147037.17, Feasible: false, Primal res.: 0.16979253, Dual res.: 0.008881426\n",
      "37776 [pslpython.model PSL] INFO --- 27454 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Inference complete.\n",
      "37777 [pslpython.model PSL] INFO --- 27454 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Writing results to Database.\n",
      "37818 [pslpython.model PSL] INFO --- 27497 [main] INFO  org.linqs.psl.application.inference.InferenceApplication  - Results committed to database.\n",
      "37830 [pslpython.model PSL] INFO --- 27509 [main] INFO  org.linqs.psl.cli.Launcher  - Inference Complete\n"
     ]
    }
   ],
   "source": [
    "psl.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the results.\n",
    "We'll get a `pandas.DataFrame` describing the targets in the `Knows` predicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.980336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0.977027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1     truth\n",
       "0  7  20  0.003016\n",
       "1  8  13  0.983496\n",
       "2  8  12  0.980336\n",
       "3  8  10  0.986562\n",
       "4  8  21  0.977027"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = psl.get_results(\"Knows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the \"truth\" values from our targets, with their probabilities from the inference provided by the PSL model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>truth</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983496</td>\n",
       "      <td>-0.016504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.980336</td>\n",
       "      <td>-0.019664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986562</td>\n",
       "      <td>-0.013438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0.977027</td>\n",
       "      <td>-0.022973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.209276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0.977246</td>\n",
       "      <td>-0.022754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.003826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.215542</td>\n",
       "      <td>-0.784458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.210734</td>\n",
       "      <td>0.210734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983735</td>\n",
       "      <td>-0.016265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0.203994</td>\n",
       "      <td>0.203994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.003626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.003170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.209062</td>\n",
       "      <td>-0.790938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>0.987337</td>\n",
       "      <td>-0.012663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.980131</td>\n",
       "      <td>-0.019869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986161</td>\n",
       "      <td>-0.013839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.209194</td>\n",
       "      <td>-0.790806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.977489</td>\n",
       "      <td>-0.022511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.997909</td>\n",
       "      <td>-0.002091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>-0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>-0.003614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>-0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.232080</td>\n",
       "      <td>-0.767920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.003832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.982482</td>\n",
       "      <td>-0.017518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.990218</td>\n",
       "      <td>-0.009782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>0.240255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.243229</td>\n",
       "      <td>-0.756771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>0.005642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>-0.011694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.994981</td>\n",
       "      <td>-0.005019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>-0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0.985908</td>\n",
       "      <td>-0.014092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999133</td>\n",
       "      <td>-0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.986136</td>\n",
       "      <td>-0.013864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991560</td>\n",
       "      <td>-0.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.003734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>-0.757102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.003269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983997</td>\n",
       "      <td>-0.016003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997324</td>\n",
       "      <td>-0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.240558</td>\n",
       "      <td>0.240558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>-0.013726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987199</td>\n",
       "      <td>-0.012801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999040</td>\n",
       "      <td>-0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.986590</td>\n",
       "      <td>-0.013410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.003461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>-0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.005654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.971274</td>\n",
       "      <td>-0.028726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211161</td>\n",
       "      <td>0.211161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.002973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>-0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970356</td>\n",
       "      <td>-0.029644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.209213</td>\n",
       "      <td>0.209213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>0.977755</td>\n",
       "      <td>-0.022245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.004392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>-0.008934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.992659</td>\n",
       "      <td>-0.007341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>-0.004637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>-0.010944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.988364</td>\n",
       "      <td>-0.011636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.006495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.006086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.230131</td>\n",
       "      <td>0.230131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>0.204121</td>\n",
       "      <td>0.204121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>0.993057</td>\n",
       "      <td>-0.006943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>0.970613</td>\n",
       "      <td>-0.029387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0.230089</td>\n",
       "      <td>0.230089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.009060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.245353</td>\n",
       "      <td>-0.754647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.007118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.986302</td>\n",
       "      <td>-0.013698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.986422</td>\n",
       "      <td>-0.013578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>-0.743717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.235546</td>\n",
       "      <td>0.235546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977544</td>\n",
       "      <td>-0.022456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.995010</td>\n",
       "      <td>-0.004990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0.981580</td>\n",
       "      <td>-0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>-0.011834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0.982193</td>\n",
       "      <td>-0.017807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0.215405</td>\n",
       "      <td>-0.784595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.990415</td>\n",
       "      <td>-0.009585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.991969</td>\n",
       "      <td>-0.008031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.003525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>-0.015945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998766</td>\n",
       "      <td>-0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977173</td>\n",
       "      <td>-0.022827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983707</td>\n",
       "      <td>-0.016293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.231897</td>\n",
       "      <td>-0.768103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.989759</td>\n",
       "      <td>-0.010241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969780</td>\n",
       "      <td>-0.030220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.008307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997905</td>\n",
       "      <td>-0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.986080</td>\n",
       "      <td>-0.013920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.986629</td>\n",
       "      <td>-0.013371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.981150</td>\n",
       "      <td>-0.018850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997053</td>\n",
       "      <td>-0.002947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998439</td>\n",
       "      <td>-0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.256431</td>\n",
       "      <td>-0.743569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>-0.754542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991622</td>\n",
       "      <td>-0.008378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235497</td>\n",
       "      <td>0.235497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986682</td>\n",
       "      <td>-0.013318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     truth      diff\n",
       "0     7  20  0.003016  0.003016\n",
       "1     8  13  0.983496 -0.016504\n",
       "2     8  12  0.980336 -0.019664\n",
       "3     8  10  0.986562 -0.013438\n",
       "4     8  21  0.977027 -0.022973\n",
       "5     9  19  0.209276  0.209276\n",
       "6     9  17  0.977246 -0.022754\n",
       "7     1  11  0.003826  0.003826\n",
       "8     0  22  0.001788  0.001788\n",
       "9    21  12  0.215542 -0.784458\n",
       "10    1  17  0.210734  0.210734\n",
       "11    1  13  0.983735 -0.016265\n",
       "12   21  17  0.203994  0.203994\n",
       "13   21  14  0.003626  0.003626\n",
       "14   21  24  0.003170  0.003170\n",
       "15    2  11  0.003014  0.003014\n",
       "16   21  22  0.209062 -0.790938\n",
       "17   22  24  0.987337 -0.012663\n",
       "18    3  12  0.980131 -0.019869\n",
       "19    3  10  0.986161 -0.013839\n",
       "20   22  21  0.209194 -0.790806\n",
       "21   23  18  0.002384  0.002384\n",
       "22    3  21  0.977489 -0.022511\n",
       "23    4  15  0.003189  0.003189\n",
       "24    5  12  0.997909 -0.002091\n",
       "25    5  13  0.998489 -0.001511\n",
       "26    5  16  0.996386 -0.003614\n",
       "27    5  17  0.997191 -0.002809\n",
       "28    5  22  0.232080 -0.767920\n",
       "29    6  17  0.003832  0.003832\n",
       "30    6  16  0.982482 -0.017518\n",
       "31    6  13  0.990218 -0.009782\n",
       "32    6  14  0.240255  0.240255\n",
       "33    6  12  0.243229 -0.756771\n",
       "34    6  19  0.005642  0.005642\n",
       "35    7  12  0.988306 -0.011694\n",
       "36    7  18  0.994981 -0.005019\n",
       "37    7  17  0.004167  0.004167\n",
       "38    7  15  0.001761  0.001761\n",
       "39    0  15  0.999255 -0.000745\n",
       "40   20  12  0.985908 -0.014092\n",
       "41    0  18  0.999133 -0.000867\n",
       "42   10   9  0.986136 -0.013864\n",
       "43   10   6  0.991560 -0.008440\n",
       "44   11   3  0.004300  0.004300\n",
       "45   11   8  0.003734  0.003734\n",
       "46   11   7  0.002611  0.002611\n",
       "47   12   6  0.242898 -0.757102\n",
       "48   13   7  0.003269  0.003269\n",
       "49   13   4  0.983997 -0.016003\n",
       "50    0   1  0.997324 -0.002676\n",
       "51   14   6  0.240558  0.240558\n",
       "52   14   3  0.986274 -0.013726\n",
       "53   14   1  0.987199 -0.012801\n",
       "54   14   0  0.999040 -0.000960\n",
       "55   14   9  0.986590 -0.013410\n",
       "56   15   1  0.003461  0.003461\n",
       "57   15   5  0.999315 -0.000685\n",
       "58   16   2  0.005654  0.005654\n",
       "59   16   8  0.971274 -0.028726\n",
       "60   16   7  0.004909  0.004909\n",
       "61   17   1  0.211161  0.211161\n",
       "62   18   8  0.002973  0.002973\n",
       "63   18   5  0.999129 -0.000871\n",
       "64   19   1  0.970356 -0.029644\n",
       "65   19   9  0.209213  0.209213\n",
       "66   13  22  0.977755 -0.022245\n",
       "67   14  17  0.004392  0.004392\n",
       "68   14  13  0.991066 -0.008934\n",
       "69   14  11  0.992659 -0.007341\n",
       "70   15  11  0.995363 -0.004637\n",
       "71   14  23  0.989056 -0.010944\n",
       "72   16  15  0.988364 -0.011636\n",
       "73   16  12  0.006495  0.006495\n",
       "74   16  23  0.006086  0.006086\n",
       "75   17  18  0.230131  0.230131\n",
       "76   17  21  0.204121  0.204121\n",
       "77   18  12  0.993057 -0.006943\n",
       "78   17  22  0.970613 -0.029387\n",
       "79   18  17  0.230089  0.230089\n",
       "80   18  15  0.000939  0.000939\n",
       "81   19  16  0.009060  0.009060\n",
       "82    7   5  0.245353 -0.754647\n",
       "83    8   3  0.007118  0.007118\n",
       "84    8   7  0.986302 -0.013698\n",
       "85    9   7  0.986422 -0.013578\n",
       "86    9   5  0.256283 -0.743717\n",
       "87    9   6  0.235546  0.235546\n",
       "88    9   1  0.977544 -0.022456\n",
       "89   10  15  0.995010 -0.004990\n",
       "90   11  19  0.981580 -0.018420\n",
       "91   12  10  0.988166 -0.011834\n",
       "92   11  22  0.982193 -0.017807\n",
       "93   12  17  0.005274  0.005274\n",
       "94   12  21  0.215405 -0.784595\n",
       "95   13  11  0.990415 -0.009585\n",
       "96   13  10  0.003452  0.003452\n",
       "97   12  24  0.991969 -0.008031\n",
       "98   20   6  0.003525  0.003525\n",
       "99   20   1  0.984055 -0.015945\n",
       "100   0   7  0.998766 -0.001234\n",
       "101  21   1  0.977173 -0.022827\n",
       "102   1   2  0.983707 -0.016293\n",
       "103  22   5  0.231897 -0.768103\n",
       "104   2   6  0.989759 -0.010241\n",
       "105  22   1  0.969780 -0.030220\n",
       "106  22   9  0.008307  0.008307\n",
       "107  23   0  0.997905 -0.002095\n",
       "108   3   7  0.986080 -0.013920\n",
       "109  23   2  0.986629 -0.013371\n",
       "110  23   9  0.981150 -0.018850\n",
       "111   4   0  0.997053 -0.002947\n",
       "112   5   2  0.998439 -0.001561\n",
       "113   5   9  0.256431 -0.743569\n",
       "114   5   7  0.245458 -0.754542\n",
       "115   6   7  0.991622 -0.008378\n",
       "116   6   9  0.235497  0.235497\n",
       "117   7   1  0.986682 -0.013318"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_val = {}\n",
    "\n",
    "for index, row in df_dat.iterrows():\n",
    "    p1 = row[0]\n",
    "    p2 = row[1]\n",
    "    key = (int(p1), int(p2))\n",
    "    dat_val[key] = row[\"truth\"]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    p1 = row[0]\n",
    "    p2 = row[1]\n",
    "    key = (int(p1), int(p2))\n",
    "    df.at[index, \"diff\"] = row[\"truth\"] - dat_val[key]\n",
    "\n",
    "pd.set_option(\"max_rows\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, which of these \"knows\" relations in the graph appears to be suspect, based on our rules plus the other evidence in the graph?\n",
    "\n",
    "Let's visualize a histogram of how the inferred probabilities are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"diff\"].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases there is little or no difference (`0.0 <= d <= 0.2`) in the probabilities for the target relations.\n",
    "However, some appear to be off by a substantial (`-0.8`) amount, which indicates problems in that part of  our graph data.\n",
    "\n",
    "The following rows show where these `foaf:knows` annotations in the graph differs significantly from their truth values predicted by PSL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>truth</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.215542</td>\n",
       "      <td>-0.784458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.209062</td>\n",
       "      <td>-0.790938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.209194</td>\n",
       "      <td>-0.790806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.232080</td>\n",
       "      <td>-0.767920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.243229</td>\n",
       "      <td>-0.756771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>-0.757102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.245353</td>\n",
       "      <td>-0.754647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>-0.743717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0.215405</td>\n",
       "      <td>-0.784595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.231897</td>\n",
       "      <td>-0.768103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.256431</td>\n",
       "      <td>-0.743569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>-0.754542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     truth      diff\n",
       "9    21  12  0.215542 -0.784458\n",
       "16   21  22  0.209062 -0.790938\n",
       "20   22  21  0.209194 -0.790806\n",
       "28    5  22  0.232080 -0.767920\n",
       "33    6  12  0.243229 -0.756771\n",
       "47   12   6  0.242898 -0.757102\n",
       "82    7   5  0.245353 -0.754647\n",
       "86    9   5  0.256283 -0.743717\n",
       "94   12  21  0.215405 -0.784595\n",
       "103  22   5  0.231897 -0.768103\n",
       "113   5   9  0.256431 -0.743569\n",
       "114   5   7  0.245458 -0.754542"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"diff\"] < -0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of [*human-in-the-loop*](https://derwen.ai/d/human-in-the-loop) practices for AI, using PSL along with a KG seems like a great way to leverage machine learning, so that the people can focus on parts of the graph that have the most uncertainty.\n",
    "And, therefore, probably provide the best ROI for investing time+cost into curation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Build a PSL model that tests the \"noodle vs. pancake\" rules used in an earlier example with our recipe KG.\n",
    "Which recipes should be annotated differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "Try representing one of the other [PSL examples](https://github.com/linqs/psl-examples/) using RDF and `kglab`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
